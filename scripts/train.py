#!/usr/bin/env python3
"""è®­ç»ƒè„šæœ¬

ä½¿ç”¨æ–¹å¼:
    python scripts/train.py
    python scripts/train.py --config configs/medium.yaml
    python scripts/train.py --dim 512 --n_layers 8
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import argparse
import torch

from llm_foundry import ModelConfig, TrainConfig, MiniLLM, DataLoader
from llm_foundry.training import Trainer
from llm_foundry.utils import get_device


def parse_args():
    parser = argparse.ArgumentParser(description='è®­ç»ƒ LLM æ¨¡å‹')

    # é…ç½®æ–‡ä»¶
    parser.add_argument('--config', type=str, default=None,
                       help='YAML é…ç½®æ–‡ä»¶è·¯å¾„')

    # æ¨¡å‹é…ç½®
    parser.add_argument('--dim', type=int, default=256,
                       help='æ¨¡å‹ç»´åº¦')
    parser.add_argument('--n_layers', type=int, default=4,
                       help='å±‚æ•°')
    parser.add_argument('--n_heads', type=int, default=8,
                       help='æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--n_kv_heads', type=int, default=4,
                       help='KV å¤´æ•°')
    parser.add_argument('--vocab_size', type=int, default=8192,
                       help='è¯è¡¨å¤§å°')
    parser.add_argument('--max_seq_len', type=int, default=256,
                       help='æœ€å¤§åºåˆ—é•¿åº¦')

    # è®­ç»ƒé…ç½®
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹é‡å¤§å°')
    parser.add_argument('--learning_rate', type=float, default=3e-4,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--max_iters', type=int, default=1000,
                       help='æœ€å¤§è¿­ä»£æ¬¡æ•°')
    parser.add_argument('--eval_interval', type=int, default=50,
                       help='è¯„ä¼°é—´éš”')

    # æ•°æ®é…ç½®
    parser.add_argument('--data_file', type=str, default='input_cn.txt',
                       help='è®­ç»ƒæ•°æ®æ–‡ä»¶')

    # è¾“å‡ºé…ç½®
    parser.add_argument('--output', type=str, default='minillm.pt',
                       help='æ¨¡å‹ä¿å­˜è·¯å¾„')

    # è®¾å¤‡é…ç½®
    parser.add_argument('--device', type=str, default='auto',
                       help='è®¡ç®—è®¾å¤‡ (cuda/mps/cpu/auto)')

    return parser.parse_args()


def main():
    args = parse_args()

    # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶,åŠ è½½å®ƒ
    if args.config:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶: {args.config}")
        # TODO: å®ç° YAML é…ç½®åŠ è½½
        print("æ³¨æ„: YAML é…ç½®åŠ è½½å°šæœªå®ç°,ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°")

    # è®¾å¤‡æ£€æµ‹
    if args.device == 'auto':
        device = get_device()
    else:
        device = args.device
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # åˆ›å»ºé…ç½®
    model_cfg = ModelConfig(
        dim=args.dim,
        n_layers=args.n_layers,
        n_heads=args.n_heads,
        n_kv_heads=args.n_kv_heads,
        vocab_size=args.vocab_size,
        max_seq_len=args.max_seq_len
    )

    train_cfg = TrainConfig(
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        max_iters=args.max_iters,
        eval_interval=args.eval_interval
    )

    print(f"\næ¨¡å‹é…ç½®:")
    print(f"  ç»´åº¦: {model_cfg.dim}")
    print(f"  å±‚æ•°: {model_cfg.n_layers}")
    print(f"  æ³¨æ„åŠ›å¤´æ•°: {model_cfg.n_heads}")
    print(f"  KV å¤´æ•°: {model_cfg.n_kv_heads}")
    print(f"  è¯è¡¨å¤§å°: {model_cfg.vocab_size}")
    print(f"  åºåˆ—é•¿åº¦: {model_cfg.max_seq_len}")

    print(f"\nè®­ç»ƒé…ç½®:")
    print(f"  æ‰¹é‡å¤§å°: {train_cfg.batch_size}")
    print(f"  å­¦ä¹ ç‡: {train_cfg.learning_rate}")
    print(f"  æœ€å¤§è¿­ä»£: {train_cfg.max_iters}")

    # åŠ è½½æ•°æ®
    print(f"\nåŠ è½½æ•°æ®: {args.data_file}")
    loader = DataLoader(
        file_path=args.data_file,
        batch_size=train_cfg.batch_size,
        block_size=model_cfg.max_seq_len,
        device=device
    )

    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = MiniLLM(model_cfg).to(device)
    print(f"æ¨¡å‹å‚æ•°é‡: {model.get_num_params()/1e6:.2f}M")

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        train_config=train_cfg,
        data_loader=loader,
        device=device
    )

    # è®­ç»ƒ
    print()
    stats = trainer.train()

    # ä¿å­˜æ¨¡å‹
    print(f"\nä¿å­˜æ¨¡å‹åˆ°: {args.output}")
    torch.save(model.state_dict(), args.output)

    print("\nè®­ç»ƒå®Œæˆ! ğŸ‰")
    print(f"  æœ€ç»ˆè®­ç»ƒæŸå¤±: {stats['train_losses'][-1]:.4f}")
    print(f"  æœ€ç»ˆéªŒè¯æŸå¤±: {stats['val_losses'][-1]:.4f}")
    print(f"  æ€»è€—æ—¶: {stats['elapsed_time']:.2f}s")


if __name__ == '__main__':
    main()
