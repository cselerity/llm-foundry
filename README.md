# LLM Foundry

> **å®ç”¨çš„å¼€æº LLM åŸºç¡€ â€”â€” ä»åŸºç¡€åˆ°ç”Ÿäº§**

ä¸€ä¸ªè½»é‡çº§ã€æ¨¡å—åŒ–çš„ Transformer è¯­è¨€æ¨¡å‹å®ç°,æ¶µç›–ä»åŸºç¡€æ¦‚å¿µåˆ°ç”Ÿäº§éƒ¨ç½²çš„å®Œæ•´æ—…ç¨‹ã€‚

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

[English](#) | [ä¸­æ–‡](#)

## âœ¨ ç‰¹æ€§

- ğŸ¯ **ç°ä»£æ¶æ„**: RoPE, GQA, SwiGLU, RMSNorm ç­‰æœ€æ–°æŠ€æœ¯
- ğŸ“¦ **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„ä»£ç ç»“æ„,æ˜“äºç†è§£å’Œæ‰©å±•
- ğŸ“ **æ•™è‚²å‹å¥½**: è¯¦ç»†çš„ä¸­æ–‡æ–‡æ¡£å’Œæ³¨é‡Š
- ğŸš€ **ç”Ÿäº§å°±ç»ª**: æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦ã€æ¨¡å‹æœåŠ¡
- ğŸ”§ **åŒæ¨¡å¼**: ç®€å•è„šæœ¬(æ•™å­¦)+ å®Œæ•´åŒ…(ç”Ÿäº§)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-org/llm-foundry.git
cd llm-foundry

# å®‰è£…ä¾èµ–
pip install -e .
```

### ç®€å•æ¨¡å¼(å¿«é€Ÿä½“éªŒ)

```bash
# è®­ç»ƒæ¨¡å‹(ä½¿ç”¨ç®€å•è„šæœ¬)
cd simple
python train.py

# ç”Ÿæˆæ–‡æœ¬
python generate.py
```

### åŒ…æ¨¡å¼(ç”Ÿäº§ä½¿ç”¨)

```python
from llm_foundry import ModelConfig, MiniLLM, Tokenizer, DataLoader

# 1. é…ç½®
cfg = ModelConfig()

# 2. åŠ è½½æ•°æ®
loader = DataLoader(batch_size=32, block_size=256)

# 3. åˆ›å»ºæ¨¡å‹
model = MiniLLM(cfg)

# 4. è®­ç»ƒ
# ... (æŸ¥çœ‹ docs/zh/training.md)
```

## ğŸ“– æ–‡æ¡£

å®Œæ•´æ–‡æ¡£è¯·è®¿é—® **[docs/](docs/README.md)**

### æ ¸å¿ƒæ–‡æ¡£

- **[å¿«é€Ÿå…¥é—¨](docs/zh/quickstart.md)** - 5åˆ†é’Ÿä¸Šæ‰‹
- **[æ¶æ„è¯¦è§£](docs/zh/architecture.md)** - æ·±å…¥ç†è§£æ¨¡å‹
- **[è®­ç»ƒæŒ‡å—](docs/zh/training.md)** - è®­ç»ƒæŠ€å·§å’Œä¼˜åŒ–
- **[Agent åä½œæŒ‡å—](AGENTS.md)** - AI Agent å¼€å‘æŒ‡å—

### ç”Ÿäº§éƒ¨ç½²

- [åˆ†å¸ƒå¼è®­ç»ƒ](docs/zh/production/distributed-training.md) - å¤š GPU è®­ç»ƒ
- [æ··åˆç²¾åº¦](docs/zh/production/mixed-precision.md) - FP16/BF16 åŠ é€Ÿ
- [æ¨¡å‹æœåŠ¡](docs/zh/production/model-serving.md) - API éƒ¨ç½²
- [æ¨ç†ä¼˜åŒ–](docs/zh/production/optimization.md) - é‡åŒ–å’ŒåŠ é€Ÿ

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
llm-foundry/
â”œâ”€â”€ src/llm_foundry/      # ä¸»åŒ…(ç”Ÿäº§ä»£ç )
â”‚   â”œâ”€â”€ config/           # é…ç½®
â”‚   â”œâ”€â”€ models/           # æ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ tokenizers/       # åˆ†è¯å™¨
â”‚   â”œâ”€â”€ data/             # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ training/         # è®­ç»ƒå·¥å…·
â”‚   â”œâ”€â”€ inference/        # æ¨ç†å·¥å…·
â”‚   â””â”€â”€ utils/            # å·¥å…·å‡½æ•°
â”œâ”€â”€ simple/               # ç®€å•è„šæœ¬(æ•™å­¦)
â”œâ”€â”€ examples/             # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ docs/                 # æ–‡æ¡£
â”œâ”€â”€ tests/                # æµ‹è¯•
â””â”€â”€ AGENTS.md             # Agent åä½œæŒ‡å—
```

## ğŸ’¡ ç¤ºä¾‹

æŸ¥çœ‹ [examples/](examples/) ç›®å½•è·å–æ›´å¤šç¤ºä¾‹:

- `01_basic_training.py` - åŸºç¡€è®­ç»ƒ
- `02_custom_data.py` - è‡ªå®šä¹‰æ•°æ®é›†
- `03_generation_sampling.py` - é‡‡æ ·ç­–ç•¥
- `04_fine_tuning.py` - æ¨¡å‹å¾®è°ƒ

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### æ•™è‚²å­¦ä¹ 
- ç†è§£ Transformer æ¶æ„
- å­¦ä¹  LLM è®­ç»ƒæµç¨‹
- å®éªŒä¸åŒçš„æ¨¡å‹è®¾è®¡

### ç ”ç©¶å¼€å‘
- å¿«é€ŸåŸå‹éªŒè¯
- æ¶æ„æ”¹è¿›å®éªŒ
- ç®—æ³•ä¼˜åŒ–æµ‹è¯•

### ç”Ÿäº§éƒ¨ç½²
- å®šåˆ¶åŒ– LLM è§£å†³æ–¹æ¡ˆ
- å‚ç›´é¢†åŸŸæ¨¡å‹è®­ç»ƒ
- ä¼ä¸šçº§éƒ¨ç½²

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **æ¡†æ¶**: PyTorch 2.0+
- **åˆ†è¯**: SentencePiece BPE
- **è®­ç»ƒ**: AdamW, æ··åˆç²¾åº¦, DDP
- **æ¨ç†**: Top-k/Top-p é‡‡æ ·, KV Cache

## ğŸ¤ è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®!

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'feat: add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. å¼€å¯ Pull Request

è¯¦è§ [AGENTS.md](AGENTS.md) äº†è§£å¼€å‘å·¥ä½œæµã€‚

## ğŸ“Š æ¨¡å‹å‚æ•°

| é…ç½® | å‚æ•°é‡ | å±‚æ•° | ç»´åº¦ | å¤´æ•° |
|------|--------|------|------|------|
| Small | ~2M | 4 | 256 | 8 |
| Medium | ~10M | 8 | 512 | 8 |
| Large | ~40M | 12 | 768 | 12 |

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸŒŸ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®çš„å¯å‘:

- [nanoGPT](https://github.com/karpathy/nanoGPT) by Andrej Karpathy
- [LLaMA](https://github.com/facebookresearch/llama) by Meta AI
- [Transformer](https://arxiv.org/abs/1706.03762) paper by Vaswani et al.

## ğŸ“ è”ç³»æ–¹å¼

- é—®é¢˜åé¦ˆ: [GitHub Issues](https://github.com/your-org/llm-foundry/issues)
- è®¨è®ºäº¤æµ: [GitHub Discussions](https://github.com/your-org/llm-foundry/discussions)

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©,è¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Star!
