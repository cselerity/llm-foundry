# LLM Foundry

> **å®ç”¨çš„å¼€æº LLM åŸºç¡€ â€”â€” ä»åŸºç¡€åˆ°ç”Ÿäº§**

ä¸€ä¸ªæ•™è‚²ä¸ç”Ÿäº§å¹¶é‡çš„ Transformer è¯­è¨€æ¨¡å‹å®ç°ï¼Œæ¶µç›–ä»åŸºç¡€å­¦ä¹ åˆ°ç”Ÿäº§éƒ¨ç½²çš„å®Œæ•´åœºæ™¯ã€‚

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

[English](#) | [ä¸­æ–‡](#)

---

## ğŸ¯ è¿™æ˜¯ä»€ä¹ˆï¼Ÿ

LLM Foundry æ˜¯ä¸€ä¸ª**æ•™è‚²ä¼˜å…ˆã€ç”Ÿäº§å°±ç»ª**çš„è¯­è¨€æ¨¡å‹å®ç°ï¼Œé‡‡ç”¨**åŒè½¨è®¾è®¡**:

- **æ•™å­¦è½¨ (tutorials/)**: å•æ–‡ä»¶å®Œæ•´å®ç°ï¼Œè¯¦ç»†æ³¨é‡Šï¼Œé€‚åˆå­¦ä¹ 
- **ç”Ÿäº§è½¨ (src/)**: æ¨¡å—åŒ–åŒ…ï¼Œå·¥ç¨‹ä¼˜åŒ–ï¼Œé€‚åˆå¼€å‘

**æ ¸å¿ƒç‰¹æ€§**: RoPE â€¢ GQA â€¢ SwiGLU â€¢ RMSNorm â€¢ ç°ä»£ Transformer æ¶æ„

---

## ğŸš€ å¿«é€Ÿå¯¼èˆª

### é¦–æ¬¡ä½¿ç”¨

**5 åˆ†é’Ÿå¿«é€Ÿä½“éªŒ** â†’ [GETTING_STARTED.md](GETTING_STARTED.md)
   - å®‰è£… â†’ è®­ç»ƒç¬¬ä¸€ä¸ªæ¨¡å‹ â†’ ç”Ÿæˆæ–‡æœ¬

**10-15 å°æ—¶ç³»ç»Ÿå­¦ä¹ ** â†’ [LEARNING_PATH.md](LEARNING_PATH.md)
   - 5 é˜¶æ®µç»“æ„åŒ–è·¯å¾„
   - ä»é›¶ç†è§£ Transformer
   - æŒæ¡æ ¸å¿ƒæŠ€æœ¯

---

### å®è·µè€…

**é’ˆå¯¹æ‚¨çš„ç¡¬ä»¶ä¼˜åŒ–** â†’ [ç¡¬ä»¶æŒ‡å—](docs/zh/hardware/)
   - [RTX 5060 æŒ‡å—](docs/zh/hardware/rtx-5060.md) - 8GB GPU (70M å‚æ•°, 30-40 åˆ†é’Ÿ)
   - [Apple Silicon æŒ‡å—](docs/zh/hardware/apple-silicon.md) - M4 Pro ä¼˜åŒ–
   - [é…ç½®é€ŸæŸ¥è¡¨](docs/zh/hardware/quick-reference.md) - å¿«é€Ÿå‚è€ƒ

---

### å¼€å‘è€… / ç ”ç©¶è€…

**æ·±å…¥æ¶æ„** â†’ [æ¶æ„æ–‡æ¡£](docs/zh/architecture/)
   - [æ ¸å¿ƒç»„ä»¶](docs/zh/architecture/components.md) - RMSNorm, RoPE, GQA, SwiGLU
   - [è®­ç»ƒç³»ç»Ÿ](docs/zh/architecture/training-system.md) - LLM è®­ç»ƒå®Œæ•´çŸ¥è¯†
   - [è®¾è®¡å†³ç­–](docs/zh/architecture/design-decisions.md) - æŠ€æœ¯é€‰å‹ç†ç”±

**è´¡çŒ®ä»£ç ** â†’ [AGENTS.md](AGENTS.md)
   - AI Agent åä½œæŒ‡å—
   - å¼€å‘å·¥ä½œæµ
   - è´¡çŒ®è§„èŒƒ

---

## âš¡ ä¸€åˆ†é’Ÿä½“éªŒ

```bash
# 1. å®‰è£…
git clone https://github.com/your-org/llm-foundry.git
cd llm-foundry
pip install -e .

# 2. è®­ç»ƒ
cd tutorials
python train.py      # è®­ç»ƒæ¨¡å‹ (~30 ç§’)

# 3. ç”Ÿæˆ
python generate.py   # ç”Ÿæˆæ–‡æœ¬
```

**è¯¦ç»†æ­¥éª¤** â†’ [GETTING_STARTED.md](GETTING_STARTED.md)

---

## ğŸ“š æ–‡æ¡£

**ä¸»å¯¼èˆª** â†’ [docs/README.md](docs/README.md)
   - æŒ‰ç”¨é€”å¯¼èˆª ("æˆ‘æƒ³...")
   - æŒ‰è§’è‰²å¯¼èˆª (åˆå­¦è€…ã€å®è·µè€…ã€å¼€å‘è€…)
   - å®Œæ•´æ–‡æ¡£ç´¢å¼•

**æ ¸å¿ƒæ–‡æ¡£**:
- [ğŸ“– å¿«é€Ÿå¼€å§‹](GETTING_STARTED.md) - 5-10 åˆ†é’Ÿä¸Šæ‰‹
- [ğŸ¯ å­¦ä¹ è·¯å¾„](LEARNING_PATH.md) - ç³»ç»Ÿå­¦ä¹ æŒ‡å—
- [ğŸ—ï¸ æ¶æ„è¯¦è§£](docs/zh/architecture/) - æ·±å…¥ç†è§£
- [ğŸ’» ç¡¬ä»¶æŒ‡å—](docs/zh/hardware/) - å¹³å°ä¼˜åŒ–
- [ğŸš€ ç”Ÿäº§éƒ¨ç½²](docs/zh/production/) - ä¼ä¸šçº§éƒ¨ç½²
- [ğŸ¤– AI Agent](AGENTS.md) - å¼€å‘åä½œ

---

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
llm-foundry/
â”œâ”€â”€ src/llm_foundry/      # ä¸»åŒ… (ç”Ÿäº§ä»£ç )
â”‚   â”œâ”€â”€ models/           # Transformer å®ç°
â”‚   â”œâ”€â”€ training/         # è®­ç»ƒå·¥å…·
â”‚   â”œâ”€â”€ inference/        # æ¨ç†å·¥å…·
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tutorials/            # æ•™å­¦è„šæœ¬ (é•œåƒ src/ åŠŸèƒ½)
â”‚   â”œâ”€â”€ model.py          # å®Œæ•´ Transformer (å•æ–‡ä»¶)
â”‚   â”œâ”€â”€ train.py          # è®­ç»ƒæµç¨‹
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docs/                 # æ–‡æ¡£
â”‚   â””â”€â”€ zh/               # ä¸­æ–‡æ–‡æ¡£
â”‚       â”œâ”€â”€ architecture/ # æ¶æ„è¯¦è§£
â”‚       â”œâ”€â”€ guides/       # å®ç”¨æŒ‡å—
â”‚       â”œâ”€â”€ hardware/     # ç¡¬ä»¶æŒ‡å—
â”‚       â””â”€â”€ production/   # ç”Ÿäº§éƒ¨ç½²
â”œâ”€â”€ examples/             # ä½¿ç”¨ç¤ºä¾‹
â””â”€â”€ tests/                # æµ‹è¯•
```

---

## âœ¨ ç‰¹æ€§

- ğŸ¯ **ç°ä»£æ¶æ„**: RoPE, GQA, SwiGLU, RMSNorm ç­‰æœ€æ–°æŠ€æœ¯
- ğŸ“¦ **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„ä»£ç ç»“æ„ï¼Œæ˜“äºç†è§£å’Œæ‰©å±•
- ğŸ“ **æ•™è‚²å‹å¥½**: è¯¦ç»†çš„ä¸­æ–‡æ–‡æ¡£å’Œæ³¨é‡Š
- ğŸš€ **ç”Ÿäº§å°±ç»ª**: åˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦ã€æ¨¡å‹æœåŠ¡
- ğŸ”§ **åŒè½¨å¹¶è¡Œ**: tutorials/ (æ•™å­¦) + src/ (ç”Ÿäº§)ï¼ŒåŠŸèƒ½å¯¹ç­‰

---

## ğŸ“Š æ¨¡å‹é…ç½®

| é…ç½® | å‚æ•°é‡ | å±‚æ•° | ç»´åº¦ | é€‚ç”¨åœºæ™¯ |
|------|--------|------|------|---------|
| Small | ~2M | 4 | 256 | å­¦ä¹ ã€CPU è®­ç»ƒ |
| Medium | ~10M | 8 | 512 | å®éªŒã€å° GPU |
| RTX 5060 | ~70M | 10 | 704 | 8GB GPU |
| Large | ~200M | 24 | 1024 | é«˜ç«¯ GPU/äº‘ |

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### æ•™è‚²å­¦ä¹ 
- ç†è§£ Transformer æ¶æ„
- å­¦ä¹  LLM è®­ç»ƒæµç¨‹
- å®éªŒæ¨¡å‹è®¾è®¡

### ç ”ç©¶å¼€å‘
- å¿«é€ŸåŸå‹éªŒè¯
- æ¶æ„æ”¹è¿›å®éªŒ
- ç®—æ³•ä¼˜åŒ–æµ‹è¯•

### ç”Ÿäº§éƒ¨ç½²
- å®šåˆ¶åŒ– LLM è§£å†³æ–¹æ¡ˆ
- å‚ç›´é¢†åŸŸæ¨¡å‹è®­ç»ƒ
- ä¼ä¸šçº§éƒ¨ç½²

---

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **æ¡†æ¶**: PyTorch 2.0+
- **æ¶æ„**: Decoder-Only Transformer
- **åˆ†è¯**: SentencePiece BPE
- **è®­ç»ƒ**: AdamW, æ··åˆç²¾åº¦, DDP/FSDP
- **æ¨ç†**: Top-k/Top-p é‡‡æ ·, KV Cache

---

## ğŸ’¡ ç¤ºä¾‹

æŸ¥çœ‹ [examples/](examples/) ç›®å½•:

- `01_basic_training.py` - åŸºç¡€è®­ç»ƒ
- `02_custom_data.py` - è‡ªå®šä¹‰æ•°æ®é›†
- `03_generation_sampling.py` - é‡‡æ ·ç­–ç•¥
- `04_fine_tuning.py` - æ¨¡å‹å¾®è°ƒ

---

## ğŸ¤ è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'feat: add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. å¼€å¯ Pull Request

è¯¦è§ [AGENTS.md](AGENTS.md) äº†è§£å¼€å‘å·¥ä½œæµã€‚

---

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

---

## ğŸŒŸ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®çš„å¯å‘:

- [nanoGPT](https://github.com/karpathy/nanoGPT) by Andrej Karpathy
- [LLaMA](https://github.com/facebookresearch/llama) by Meta AI
- [Transformer](https://arxiv.org/abs/1706.03762) paper by Vaswani et al.

---

## ğŸ“ è”ç³»æ–¹å¼

- é—®é¢˜åé¦ˆ: [GitHub Issues](https://github.com/your-org/llm-foundry/issues)
- è®¨è®ºäº¤æµ: [GitHub Discussions](https://github.com/your-org/llm-foundry/discussions)

---

â­ **å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Starï¼**
