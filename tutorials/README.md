# Tutorials - è¯­è¨€æ¨¡å‹è®­ç»ƒå®Œå…¨æŒ‡å—

> **å®šä½**: è¿™ä¸æ˜¯ç®€åŒ–ç‰ˆæœ¬,è€Œæ˜¯ä¸»å·¥ç¨‹æ ¸å¿ƒåŠŸèƒ½çš„**æ•™å­¦å±•ç¤º** + **å®Œæ•´çš„è®­ç»ƒçŸ¥è¯†ä½“ç³»**

æœ¬ç›®å½•æä¾›ç‹¬ç«‹è¿è¡Œçš„æ•™ç¨‹è„šæœ¬,å¸®åŠ©æ‚¨é€šè¿‡å®Œæ•´çš„ã€å¯è¿è¡Œçš„ä»£ç ç†è§£ LLM Foundry çš„æ ¸å¿ƒæ¦‚å¿µå’Œå·¥ä½œæµç¨‹,åŒæ—¶ç³»ç»Ÿæ€§åœ°å­¦ä¹ å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒçš„é€šç”¨çŸ¥è¯†å’Œä¸šç•Œæœ€ä½³å®è·µã€‚

---

## ğŸ“– ç›®å½•

- [æ–°æ‰‹æŒ‡å—](#-æ–°æ‰‹æŒ‡å—)
- [æ•™ç¨‹æ–‡ä»¶](#-æ•™ç¨‹æ–‡ä»¶)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [**LLM è®­ç»ƒå®Œæ•´çŸ¥è¯†ä½“ç³»**](#-llm-è®­ç»ƒå®Œæ•´çŸ¥è¯†ä½“ç³»)
  - [è®­ç»ƒå…¨æµç¨‹](#1-è®­ç»ƒå…¨æµç¨‹æ¦‚è§ˆ)
  - [æ ¸å¿ƒæŠ€æœ¯è¯¦è§£](#2-æ ¸å¿ƒæŠ€æœ¯è¯¦è§£)
  - [ä¸šç•Œæœ€ä½³å®è·µ](#3-ä¸šç•Œæœ€ä½³å®è·µå¤§å‚ç»éªŒ)
  - [ä¼˜åŒ–æŠ€å·§](#4-è®­ç»ƒä¼˜åŒ–æŠ€å·§)
- [ç¡¬ä»¶é…ç½®æŒ‡å—](#-ç¡¬ä»¶é…ç½®æŒ‡å—)

---

## ğŸ“– æ–°æ‰‹æŒ‡å—

**ç¬¬ä¸€æ¬¡å­¦ä¹ ?** å»ºè®®å…ˆæŸ¥çœ‹å®Œæ•´çš„å­¦ä¹ è·¯å¾„:

ğŸ‘‰ **[å­¦ä¹ è·¯å¾„æŒ‡å— (../LEARNING_PATH.md)](../LEARNING_PATH.md)**

å­¦ä¹ è·¯å¾„å°†å‘Šè¯‰æ‚¨:
- åº”è¯¥æŒ‰ä»€ä¹ˆé¡ºåºé˜…è¯»ä»£ç 
- æ¯ä¸ªæ–‡ä»¶çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ä»€ä¹ˆ
- å¦‚ä½•é€šè¿‡å®è·µåŠ æ·±ç†è§£

---

## ğŸ¯ æ•™ç¨‹å®šä½

è¿™äº›æ•™ç¨‹è„šæœ¬æ˜¯ `src/llm_foundry/` ä¸»å·¥ç¨‹çš„**æ•™å­¦é•œåƒ**:

```
src/llm_foundry/           tutorials/
(å·¥ç¨‹åŒ–å®ç°)          â†’   (æ•™å­¦å±•ç¤º)
â”œâ”€â”€ models/            â†’   model.py (å®Œæ•´å±•ç¤º)
â”œâ”€â”€ training/          â†’   train.py (æµç¨‹å±•ç¤º)
â”œâ”€â”€ inference/         â†’   generate.py (ç”¨æ³•å±•ç¤º)
â”œâ”€â”€ config/            â†’   config.py (é…ç½®å®šä¹‰)
â”œâ”€â”€ tokenizers/        â†’   tokenizer.py (åˆ†è¯å™¨)
â””â”€â”€ data/              â†’   dataloader.py (æ•°æ®åŠ è½½)
```

**å…³é”®ç‰¹ç‚¹**:
- âœ… **åŠŸèƒ½å®Œæ•´**: ä¸ä¸»å·¥ç¨‹åŠŸèƒ½å¯¹ç­‰,ä¸æ˜¯ç®€åŒ–ç‰ˆ
- âœ… **ç‹¬ç«‹è¿è¡Œ**: å•æ–‡ä»¶å³å¯è¿è¡Œ,ä¾¿äºå­¦ä¹ 
- âœ… **è¯¦ç»†æ³¨é‡Š**: ä»£ç ä¸­åŒ…å«ä¸°å¯Œçš„æ•™å­¦æ³¨é‡Š
- âœ… **æ•™å­¦ä¼˜å…ˆ**: ä»£ç ç»“æ„ä¼˜åŒ–ä¸ºæ•™å­¦å‹å¥½

---

## ğŸ“š æ•™ç¨‹æ–‡ä»¶

### æ ¸å¿ƒæ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ | å¯¹åº”ä¸»å·¥ç¨‹æ¨¡å— | ä»£ç è¡Œæ•° |
|------|------|----------------|----------|
| **[config.py](config.py)** | é…ç½®ç±»å®šä¹‰ | `src/llm_foundry/config/` | ~700 è¡Œ |
| **[model.py](model.py)** | å®Œæ•´çš„ Transformer å®ç° | `src/llm_foundry/models/` | ~630 è¡Œ |
| **[tokenizer.py](tokenizer.py)** | SentencePiece åˆ†è¯å™¨ | `src/llm_foundry/tokenizers/` | ~530 è¡Œ |
| **[dataloader.py](dataloader.py)** | æ•°æ®åŠ è½½å’Œå¤„ç† | `src/llm_foundry/data/` | ~430 è¡Œ |
| **[train.py](train.py)** | è®­ç»ƒæµç¨‹ | `src/llm_foundry/training/` | ~420 è¡Œ |
| **[generate.py](generate.py)** | æ–‡æœ¬ç”Ÿæˆ | `src/llm_foundry/inference/` | ~480 è¡Œ |

### ä¼˜åŒ–è„šæœ¬

| æ–‡ä»¶ | è¯´æ˜ | é€‚ç”¨ç¡¬ä»¶ |
|------|------|----------|
| **[train_rtx5060.py](train_rtx5060.py)** | RTX 5060 ä¼˜åŒ–è®­ç»ƒ | NVIDIA GPU (8GB) |
| **[train_m4pro.py](train_m4pro.py)** | Apple M4 Pro ä¼˜åŒ–è®­ç»ƒ | Apple Silicon (32GB) |

### æ–‡æ¡£

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| **[RTX5060_GUIDE.md](RTX5060_GUIDE.md)** | RTX 5060 å®Œæ•´ä½¿ç”¨æŒ‡å— |
| **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** | å¿«é€Ÿå‚è€ƒå¡ç‰‡ |
| **README.md** (æœ¬æ–‡ä»¶) | å®Œæ•´è®­ç»ƒçŸ¥è¯†ä½“ç³» |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€è®­ç»ƒ (é€‚åˆå­¦ä¹ )

```bash
cd tutorials
python train.py      # è®­ç»ƒæ¨¡å‹ (å°å‹é…ç½®)
python generate.py   # ç”Ÿæˆæ–‡æœ¬
```

### 2. RTX 5060 ä¼˜åŒ–è®­ç»ƒ

```bash
python train_rtx5060.py  # 70M å‚æ•°, 30-40 åˆ†é’Ÿ
```

### 3. Apple M4 Pro ä¼˜åŒ–è®­ç»ƒ

```bash
python train_m4pro.py    # 68M å‚æ•°, 40-60 åˆ†é’Ÿ
```

---

## ğŸ“ LLM è®­ç»ƒå®Œæ•´çŸ¥è¯†ä½“ç³»

### 1. è®­ç»ƒå…¨æµç¨‹æ¦‚è§ˆ

å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ˜¯ä¸€ä¸ªå¤æ‚çš„ç³»ç»Ÿå·¥ç¨‹,å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªé˜¶æ®µ:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM è®­ç»ƒå®Œæ•´æµç¨‹                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  é˜¶æ®µ 1: æ•°æ®å‡†å¤‡ (Data Preparation)                            â”‚
â”‚  â”œâ”€ æ•°æ®æ”¶é›†ä¸æ¸…æ´—                                              â”‚
â”‚  â”œâ”€ æ•°æ®å»é‡ä¸è¿‡æ»¤                                              â”‚
â”‚  â”œâ”€ æ•°æ®æ ¼å¼åŒ–                                                   â”‚
â”‚  â””â”€ åˆ†è¯å™¨è®­ç»ƒ                                                   â”‚
â”‚                                                                  â”‚
â”‚  é˜¶æ®µ 2: é¢„è®­ç»ƒ (Pre-training)                                  â”‚
â”‚  â”œâ”€ éšæœºåˆå§‹åŒ–                                                   â”‚
â”‚  â”œâ”€ å¤§è§„æ¨¡æ— ç›‘ç£è®­ç»ƒ                                            â”‚
â”‚  â”œâ”€ å­¦ä¹ é€šç”¨è¯­è¨€çŸ¥è¯†                                            â”‚
â”‚  â””â”€ è¾“å‡º: Base Model                                            â”‚
â”‚                                                                  â”‚
â”‚  é˜¶æ®µ 3: ç›‘ç£å¾®è°ƒ (Supervised Fine-tuning, SFT)                â”‚
â”‚  â”œâ”€ ä½¿ç”¨é«˜è´¨é‡æŒ‡ä»¤æ•°æ®                                          â”‚
â”‚  â”œâ”€ å­¦ä¹ éµå¾ªæŒ‡ä»¤çš„èƒ½åŠ›                                          â”‚
â”‚  â”œâ”€ å¯¹è¯æ ¼å¼è®­ç»ƒ                                                 â”‚
â”‚  â””â”€ è¾“å‡º: SFT Model                                             â”‚
â”‚                                                                  â”‚
â”‚  é˜¶æ®µ 4: å¥–åŠ±å»ºæ¨¡ (Reward Modeling)                             â”‚
â”‚  â”œâ”€ æ”¶é›†äººç±»åå¥½æ•°æ®                                            â”‚
â”‚  â”œâ”€ è®­ç»ƒå¥–åŠ±æ¨¡å‹                                                 â”‚
â”‚  â””â”€ è¾“å‡º: Reward Model                                          â”‚
â”‚                                                                  â”‚
â”‚  é˜¶æ®µ 5: å¼ºåŒ–å­¦ä¹  (RLHF/RLAIF)                                  â”‚
â”‚  â”œâ”€ ä½¿ç”¨ PPO/DPO ç­‰ç®—æ³•                                         â”‚
â”‚  â”œâ”€ åŸºäºå¥–åŠ±æ¨¡å‹ä¼˜åŒ–                                            â”‚
â”‚  â”œâ”€ å¯¹é½äººç±»ä»·å€¼è§‚                                              â”‚
â”‚  â””â”€ è¾“å‡º: Final Model                                           â”‚
â”‚                                                                  â”‚
â”‚  é˜¶æ®µ 6: è¯„ä¼°ä¸éƒ¨ç½² (Evaluation & Deployment)                   â”‚
â”‚  â”œâ”€ åŸºå‡†æµ‹è¯•è¯„ä¼°                                                 â”‚
â”‚  â”œâ”€ å®‰å…¨æ€§æµ‹è¯•                                                   â”‚
â”‚  â”œâ”€ æ¨¡å‹é‡åŒ–ä¸å‹ç¼©                                              â”‚
â”‚  â””â”€ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²                                                 â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æ ¸å¿ƒæŠ€æœ¯è¯¦è§£

#### 2.1 æ•°æ®å‡†å¤‡é˜¶æ®µ

**æ¶‰åŠæŠ€æœ¯:**

1. **æ•°æ®æ”¶é›†**
   - ç½‘é¡µçˆ¬å– (Common Crawl)
   - ä¹¦ç±ã€è®ºæ–‡ã€ä»£ç 
   - å¤šè¯­è¨€æ•°æ®
   - ä¸“ä¸šé¢†åŸŸæ•°æ®

2. **æ•°æ®æ¸…æ´—**
   ```python
   # ç¤ºä¾‹: æ•°æ®æ¸…æ´—æµç¨‹
   def clean_text(text):
       # 1. ç§»é™¤ä½è´¨é‡å†…å®¹
       text = remove_ads(text)
       text = remove_boilerplate(text)

       # 2. è§„èŒƒåŒ–
       text = normalize_whitespace(text)
       text = fix_encoding(text)

       # 3. è¿‡æ»¤
       if is_low_quality(text):
           return None

       return text
   ```

3. **æ•°æ®å»é‡**
   - ç²¾ç¡®å»é‡: Hash åŒ¹é…
   - è¿‘ä¼¼å»é‡: MinHash, SimHash
   - è·¨æ•°æ®é›†å»é‡

4. **åˆ†è¯å™¨è®­ç»ƒ**
   - BPE (Byte Pair Encoding)
   - WordPiece
   - SentencePiece
   - æœ¬é¡¹ç›®ä½¿ç”¨: **SentencePiece BPE**

**å¤§å‚å®è·µ:**
- **OpenAI**: ä½¿ç”¨ tiktoken (BPE å˜ç§)
- **Google**: ä½¿ç”¨ SentencePiece
- **Meta**: LLaMA ä½¿ç”¨ SentencePiece
- **Anthropic**: ç±»ä¼¼ GPT çš„ BPE

**æœ€ä½³å®è·µ:**
```python
# è¯æ±‡è¡¨å¤§å°é€‰æ‹©
vocab_size_guide = {
    "ä¸­æ–‡ä¸ºä¸»": "16k-32k",      # æ±‰å­—å¤š,éœ€è¦æ›´å¤§
    "è‹±æ–‡ä¸ºä¸»": "8k-16k",        # ç›¸å¯¹å›ºå®š
    "å¤šè¯­è¨€": "32k-64k",         # è¦†ç›–å¤šç§è¯­è¨€
    "ä»£ç ": "32k-50k",           # å˜é‡åã€API å¤šæ ·
}
```

#### 2.2 é¢„è®­ç»ƒé˜¶æ®µ

**æ ¸å¿ƒç›®æ ‡:** å­¦ä¹ é€šç”¨çš„è¯­è¨€çŸ¥è¯†å’Œä¸–ç•ŒçŸ¥è¯†

**è®­ç»ƒä»»åŠ¡:**
1. **å› æœè¯­è¨€å»ºæ¨¡ (Causal LM)**
   - ä»»åŠ¡: ç»™å®šå‰æ–‡,é¢„æµ‹ä¸‹ä¸€ä¸ª token
   - æŸå¤±: äº¤å‰ç†µæŸå¤±
   - æœ¬é¡¹ç›®å®ç°: `train.py`

2. **æ©ç è¯­è¨€å»ºæ¨¡ (Masked LM)**
   - BERT é£æ ¼
   - é€‚åˆç†è§£ä»»åŠ¡
   - ä¸é€‚åˆç”Ÿæˆä»»åŠ¡

**å…³é”®æŠ€æœ¯:**

1. **æ¨¡å‹æ¶æ„**
   ```
   ç°ä»£ LLM æ ‡é…:
   â”œâ”€ Transformer Decoder-Only
   â”œâ”€ RoPE ä½ç½®ç¼–ç 
   â”œâ”€ GQA/MQA æ³¨æ„åŠ›
   â”œâ”€ SwiGLU æ¿€æ´»
   â”œâ”€ RMSNorm å½’ä¸€åŒ–
   â””â”€ Pre-normalization

   æœ¬é¡¹ç›®å®ç°: model.py (å®Œæ•´å®ç°)
   ```

2. **ä¼˜åŒ–å™¨**
   - **AdamW**: ä¸šç•Œæ ‡å‡†
   - Weight Decay: é˜²æ­¢è¿‡æ‹Ÿåˆ
   - Gradient Clipping: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸

   ```python
   # æ ‡å‡†é…ç½®
   optimizer = torch.optim.AdamW(
       model.parameters(),
       lr=3e-4,              # å­¦ä¹ ç‡
       betas=(0.9, 0.95),    # åŠ¨é‡å‚æ•°
       weight_decay=0.1      # æƒé‡è¡°å‡
   )
   ```

3. **å­¦ä¹ ç‡è°ƒåº¦**
   ```python
   # Cosine è¡°å‡ + Warmup
   def get_lr(step, warmup_steps, max_steps, max_lr, min_lr):
       if step < warmup_steps:
           # Linear warmup
           return max_lr * step / warmup_steps

       # Cosine decay
       progress = (step - warmup_steps) / (max_steps - warmup_steps)
       return min_lr + 0.5 * (max_lr - min_lr) * (1 + cos(pi * progress))
   ```

**å¤§å‚å®è·µ:**

| å…¬å¸ | æ¨¡å‹ | è§„æ¨¡ | è®­ç»ƒæ•°æ® | è®­ç»ƒæ—¶é•¿ |
|------|------|------|----------|----------|
| **OpenAI** | GPT-4 | 1.76T | æœªçŸ¥ | æ•°æœˆ |
| **Google** | PaLM 2 | 340B | 3.6T tokens | æ•°æœˆ |
| **Meta** | LLaMA 2 | 70B | 2T tokens | 1.7M GPU å°æ—¶ |
| **Anthropic** | Claude 3 | æœªçŸ¥ | æœªçŸ¥ | æ•°æœˆ |
| **Mistral** | Mixtral 8x7B | 47B | æœªçŸ¥ | æ•°å‘¨ |

**æœ€ä½³å®è·µ:**

1. **æ•°æ®è´¨é‡ > æ•°æ®æ•°é‡**
   - ç²¾å¿ƒç­›é€‰çš„ 1T tokens > ç²—ç³™çš„ 10T tokens
   - æ•°æ®å¤šæ ·æ€§å¾ˆé‡è¦

2. **è®­ç»ƒç¨³å®šæ€§**
   ```python
   # ç›‘æ§å…³é”®æŒ‡æ ‡
   metrics_to_monitor = {
       "loss": "åº”è¯¥å¹³ç¨³ä¸‹é™",
       "gradient_norm": "æ£€æµ‹æ¢¯åº¦çˆ†ç‚¸",
       "learning_rate": "è°ƒåº¦æ˜¯å¦æ­£å¸¸",
       "perplexity": "æ¨¡å‹å›°æƒ‘åº¦",
   }
   ```

3. **æ£€æŸ¥ç‚¹ç­–ç•¥**
   - å®šæœŸä¿å­˜ (æ¯ 1000-5000 steps)
   - ä¿ç•™å¤šä¸ªæ£€æŸ¥ç‚¹
   - ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€

#### 2.3 ç›‘ç£å¾®è°ƒ (SFT) é˜¶æ®µ

**æ ¸å¿ƒç›®æ ‡:** æ•™ä¼šæ¨¡å‹éµå¾ªæŒ‡ä»¤,è¿›è¡Œå¯¹è¯

**æ•°æ®æ ¼å¼:**
```json
{
  "instruction": "è§£é‡Šé‡å­çº ç¼ ",
  "input": "",
  "output": "é‡å­çº ç¼ æ˜¯æŒ‡ä¸¤ä¸ªæˆ–å¤šä¸ªç²’å­..."
}
```

**å…³é”®æŠ€æœ¯:**

1. **æŒ‡ä»¤æ ¼å¼åŒ–**
   ```python
   # Alpaca æ ¼å¼
   prompt_template = """Below is an instruction that describes a task.

   ### Instruction:
   {instruction}

   ### Response:
   {response}"""

   # ChatML æ ¼å¼ (OpenAI)
   prompt_template = """<|im_start|>system
   {system_prompt}<|im_end|>
   <|im_start|>user
   {user_message}<|im_end|>
   <|im_start|>assistant
   {assistant_message}<|im_end|>"""
   ```

2. **è®­ç»ƒæŠ€å·§**
   - **ä½å­¦ä¹ ç‡**: 1e-5 åˆ° 5e-5 (æ¯”é¢„è®­ç»ƒå° 10 å€)
   - **å°‘é‡ epoch**: 1-3 ä¸ª epoch (é˜²æ­¢è¿‡æ‹Ÿåˆ)
   - **é«˜è´¨é‡æ•°æ®**: å‡ åƒåˆ°å‡ ä¸‡æ¡å³å¯

**å¤§å‚å®è·µ:**
- **OpenAI**: InstructGPT ä½¿ç”¨ ~13k æŒ‡ä»¤æ•°æ®
- **Meta**: LLaMA 2 ä½¿ç”¨æ•°åä¸‡æ¡å¯¹è¯æ•°æ®
- **Anthropic**: Constitutional AI æ–¹æ³•

#### 2.4 å¥–åŠ±å»ºæ¨¡é˜¶æ®µ

**æ ¸å¿ƒç›®æ ‡:** è®­ç»ƒä¸€ä¸ªè¯„åˆ†æ¨¡å‹,è¯„ä¼°å›å¤è´¨é‡

**æ•°æ®æ”¶é›†:**
```python
# äººç±»åå¥½æ•°æ®
preference_data = {
    "prompt": "å†™ä¸€é¦–è¯—",
    "response_a": "æ˜¥çœ ä¸è§‰æ™“...",  # å¥½
    "response_b": "asdf qwer...",   # å·®
    "preference": "A"  # äººç±»é€‰æ‹©
}
```

**è®­ç»ƒç›®æ ‡:**
```python
# Bradley-Terry æ¨¡å‹
loss = -log(sigmoid(r(x, y_w) - r(x, y_l)))
# r(x, y_w): è¢«é€‰ä¸­å›å¤çš„å¥–åŠ±
# r(x, y_l): è¢«æ‹’ç»å›å¤çš„å¥–åŠ±
```

#### 2.5 å¼ºåŒ–å­¦ä¹  (RLHF) é˜¶æ®µ

**æ ¸å¿ƒç®—æ³•:**

1. **PPO (Proximal Policy Optimization)**
   - OpenAI ä½¿ç”¨
   - å¤æ‚ä½†æ•ˆæœå¥½
   - éœ€è¦ 4 ä¸ªæ¨¡å‹åŒæ—¶è¿è¡Œ

2. **DPO (Direct Preference Optimization)**
   - 2023 å¹´æ–°æ–¹æ³•
   - ä¸éœ€è¦å¥–åŠ±æ¨¡å‹
   - è®­ç»ƒæ›´ç®€å•

**è®­ç»ƒæµç¨‹ (PPO):**
```
1. ä½¿ç”¨ SFT æ¨¡å‹ç”Ÿæˆå›å¤
2. å¥–åŠ±æ¨¡å‹è¯„åˆ†
3. è®¡ç®— PPO æŸå¤±
4. æ›´æ–°ç­–ç•¥æ¨¡å‹
5. é‡å¤
```

**å¤§å‚å®è·µ:**
- **OpenAI**: PPO (ChatGPT, GPT-4)
- **Anthropic**: Constitutional AI + RLHF
- **Meta**: RLHF (LLaMA 2 Chat)

#### 2.6 è¯„ä¼°ä¸éƒ¨ç½²é˜¶æ®µ

**è¯„ä¼°ç»´åº¦:**

1. **èƒ½åŠ›è¯„ä¼°**
   - MMLU (å¤šä»»åŠ¡ç†è§£)
   - HumanEval (ä»£ç èƒ½åŠ›)
   - GSM8K (æ•°å­¦æ¨ç†)
   - BBH (å›°éš¾æ¨ç†)

2. **å®‰å…¨æ€§è¯„ä¼°**
   - TruthfulQA (çœŸå®æ€§)
   - ToxiGen (æ¯’æ€§æ£€æµ‹)
   - Bias æµ‹è¯• (åè§æ£€æµ‹)

3. **äººç±»è¯„ä¼°**
   - Elo è¯„åˆ†
   - ç›²æµ‹å¯¹æ¯”
   - ç”¨æˆ·åé¦ˆ

**éƒ¨ç½²ä¼˜åŒ–:**

1. **æ¨¡å‹é‡åŒ–**
   ```python
   é‡åŒ–æ–¹æ³•:
   â”œâ”€ GPTQ: 4-bit é‡åŒ–
   â”œâ”€ AWQ: æ¿€æ´»æ„ŸçŸ¥é‡åŒ–
   â”œâ”€ GGUF: CPU æ¨ç†ä¼˜åŒ–
   â””â”€ INT8/INT4: æ•´æ•°é‡åŒ–

   æ•ˆæœ: å†…å­˜å‡å°‘ 50-75%, é€Ÿåº¦æå‡ 2-4 å€
   ```

2. **æ¨ç†ä¼˜åŒ–**
   - KV Cache: ç¼“å­˜æ³¨æ„åŠ›çŠ¶æ€
   - Flash Attention: å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›
   - Continuous Batching: åŠ¨æ€æ‰¹å¤„ç†
   - Speculative Decoding: æ¨æµ‹è§£ç 

3. **åˆ†å¸ƒå¼æ¨ç†**
   - Tensor Parallelism: å¼ é‡å¹¶è¡Œ
   - Pipeline Parallelism: æµæ°´çº¿å¹¶è¡Œ
   - Model Sharding: æ¨¡å‹åˆ†ç‰‡

### 3. ä¸šç•Œæœ€ä½³å®è·µ (å¤§å‚ç»éªŒ)

#### 3.1 OpenAI çš„ç»éªŒ

**å…³é”®å†³ç­–:**
1. **è§„æ¨¡æ³•åˆ™**: æ›´å¤§çš„æ¨¡å‹ + æ›´å¤šæ•°æ® = æ›´å¥½çš„æ€§èƒ½
2. **å¯¹é½ç¨**: RLHF ä¼šè½»å¾®é™ä½æŸäº›èƒ½åŠ›,ä½†å¯¹é½å¾ˆé‡è¦
3. **è¿­ä»£å¼€å‘**: GPT-3 â†’ InstructGPT â†’ ChatGPT â†’ GPT-4

**è®­ç»ƒæŠ€å·§:**
- ä½¿ç”¨é«˜è´¨é‡çš„äººç±»åé¦ˆ
- ä¸¥æ ¼çš„å®‰å…¨æ€§æµ‹è¯•
- æŒç»­çš„ç›‘æ§å’Œæ›´æ–°

#### 3.2 Meta çš„å¼€æºç­–ç•¥

**LLaMA ç³»åˆ—ç»éªŒ:**
1. **æ•°æ®å¤šæ ·æ€§**: æ¥è‡ªä¸åŒé¢†åŸŸå’Œè¯­è¨€
2. **è®­ç»ƒæ•ˆç‡**: ä¼˜åŒ–çš„è®­ç»ƒæµç¨‹,é™ä½æˆæœ¬
3. **å¼€æºå…±äº«**: å‘å¸ƒæ¨¡å‹æƒé‡,æ¨åŠ¨ç ”ç©¶

**æŠ€æœ¯åˆ›æ–°:**
- GQA: åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ› (LLaMA 2)
- RoPE: æ—‹è½¬ä½ç½®ç¼–ç 
- RMSNorm: æ›¿ä»£ LayerNorm

#### 3.3 Anthropic çš„å¯¹é½æ–¹æ³•

**Constitutional AI:**
1. **è‡ªæˆ‘æ‰¹è¯„**: æ¨¡å‹è¯„ä¼°è‡ªå·±çš„è¾“å‡º
2. **å®ªæ³•åŸåˆ™**: å®šä¹‰ä¸€å¥—è¡Œä¸ºå‡†åˆ™
3. **è¿­ä»£æ”¹è¿›**: å¤šè½®ä¼˜åŒ–

**é‡ç‚¹:**
- å®‰å…¨æ€§ä¼˜å…ˆ
- å¯è§£é‡Šæ€§
- ä»·å€¼è§‚å¯¹é½

#### 3.4 Google çš„å·¥ç¨‹åŒ–

**PaLM/Gemini ç»éªŒ:**
1. **åŸºç¡€è®¾æ–½**: TPU é›†ç¾¤,é«˜æ•ˆè®­ç»ƒ
2. **å¤šæ¨¡æ€**: æ–‡æœ¬ + å›¾åƒ + éŸ³é¢‘
3. **é•¿ä¸Šä¸‹æ–‡**: æ”¯æŒæ›´é•¿çš„è¾“å…¥

### 4. è®­ç»ƒä¼˜åŒ–æŠ€å·§

#### 4.1 æå‡è®­ç»ƒé€Ÿåº¦

**ç¡¬ä»¶å±‚é¢:**
```python
ä¼˜åŒ–ç­–ç•¥:
â”œâ”€ ä½¿ç”¨æ›´å¿«çš„ GPU (A100 > V100 > RTX 4090)
â”œâ”€ å¢åŠ  GPU æ•°é‡ (åˆ†å¸ƒå¼è®­ç»ƒ)
â”œâ”€ ä½¿ç”¨ NVLink è¿æ¥ GPU
â”œâ”€ ä¼˜åŒ–æ•°æ®åŠ è½½ (å¤šçº¿ç¨‹ã€é¢„å–)
â””â”€ ä½¿ç”¨ SSD å­˜å‚¨æ•°æ®
```

**è½¯ä»¶å±‚é¢:**
```python
# 1. æ··åˆç²¾åº¦è®­ç»ƒ (FP16/BF16)
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    output = model(input)
    loss = criterion(output, target)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()

# 2. æ¢¯åº¦ç´¯ç§¯ (æ¨¡æ‹Ÿæ›´å¤§çš„ batch size)
accumulation_steps = 4
for i, (input, target) in enumerate(dataloader):
    output = model(input)
    loss = loss_fn(output, target) / accumulation_steps
    loss.backward()

    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()

# 3. PyTorch ç¼–è¯‘ (PyTorch 2.0+)
model = torch.compile(model)  # 20-30% é€Ÿåº¦æå‡
```

**åˆ†å¸ƒå¼è®­ç»ƒ:**
```python
# DDP (Data Parallel)
from torch.nn.parallel import DistributedDataParallel as DDP

model = DDP(model, device_ids=[local_rank])

# FSDP (Fully Sharded Data Parallel)
from torch.distributed.fsdp import FullyShardedDataParallel as FSDP

model = FSDP(model)  # æ”¯æŒæ›´å¤§çš„æ¨¡å‹
```

#### 4.2 å‡å°‘å†…å­˜å ç”¨

**æŠ€æœ¯æ‰‹æ®µ:**

1. **æ¢¯åº¦æ£€æŸ¥ç‚¹ (Gradient Checkpointing)**
   ```python
   from torch.utils.checkpoint import checkpoint

   # ä¸ä¿å­˜ä¸­é—´æ¿€æ´»å€¼,ç”¨æ—¶é‡æ–°è®¡ç®—
   output = checkpoint(layer, input)
   # å†…å­˜: â†“ 50%, æ—¶é—´: â†‘ 20%
   ```

2. **ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡**
   ```python
   # ZeRO (Zero Redundancy Optimizer)
   # Stage 1: ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡
   # Stage 2: + æ¢¯åº¦åˆ†ç‰‡
   # Stage 3: + å‚æ•°åˆ†ç‰‡
   ```

3. **æ¿€æ´»å€¼é‡è®¡ç®—**
   ```python
   # Selective recomputation
   # åªé‡è®¡ç®—ä¾¿å®œçš„æ“ä½œ,ç¼“å­˜è´µçš„æ“ä½œ
   ```

#### 4.3 æå‡æ¨¡å‹è´¨é‡

**æ•°æ®å±‚é¢:**
1. **æ•°æ®æ¸…æ´—**: ç§»é™¤ä½è´¨é‡æ•°æ®
2. **æ•°æ®å¹³è¡¡**: ä¸åŒé¢†åŸŸçš„æ•°æ®å¹³è¡¡
3. **æ•°æ®å¢å¼º**: å›è¯‘ã€æ”¹å†™ç­‰

**æ¨¡å‹å±‚é¢:**
1. **æ¶æ„æ”¹è¿›**:
   - ä½¿ç”¨ RoPE (ç›¸å¯¹ä½ç½®ç¼–ç )
   - ä½¿ç”¨ GQA (åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›)
   - ä½¿ç”¨ SwiGLU (æ¿€æ´»å‡½æ•°)

2. **è®­ç»ƒæŠ€å·§**:
   - Warmup + Cosine è¡°å‡
   - æ¢¯åº¦è£å‰ª
   - Weight Decay

3. **æ­£åˆ™åŒ–**:
   - Dropout (0.1-0.2)
   - Label Smoothing
   - Stochastic Depth

#### 4.4 é¿å…å¸¸è§é—®é¢˜

**é—®é¢˜ 1: æŸå¤±ä¸ä¸‹é™**
```python
è§£å†³æ–¹æ¡ˆ:
1. æ£€æŸ¥å­¦ä¹ ç‡ (å¯èƒ½å¤ªå¤§æˆ–å¤ªå°)
2. æ£€æŸ¥æ•°æ® (æ˜¯å¦æœ‰å¼‚å¸¸å€¼)
3. æ£€æŸ¥æ¢¯åº¦ (æ˜¯å¦æœ‰æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸)
4. å°è¯•æ›´ç®€å•çš„æ¨¡å‹
```

**é—®é¢˜ 2: è¿‡æ‹Ÿåˆ**
```python
è§£å†³æ–¹æ¡ˆ:
1. å¢åŠ  Dropout
2. å¢åŠ  Weight Decay
3. å‡å°‘æ¨¡å‹å¤§å°
4. å¢åŠ è®­ç»ƒæ•°æ®
5. ä½¿ç”¨æ•°æ®å¢å¼º
```

**é—®é¢˜ 3: è®­ç»ƒä¸ç¨³å®š**
```python
è§£å†³æ–¹æ¡ˆ:
1. é™ä½å­¦ä¹ ç‡
2. å¢åŠ  Gradient Clipping
3. ä½¿ç”¨ Warmup
4. æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§ (ä½¿ç”¨ BF16 è€Œä¸æ˜¯ FP16)
```

---

## ğŸ’» ç¡¬ä»¶é…ç½®æŒ‡å—

### æ¨èé…ç½®å¯¹æ¯”

| ç”¨é€” | GPU | æ˜¾å­˜ | ç³»ç»Ÿå†…å­˜ | æ¨¡å‹è§„æ¨¡ | è®­ç»ƒæ—¶é—´* |
|------|-----|------|----------|----------|-----------|
| **å­¦ä¹ ** | CPU | - | 8GB | 2M | 10-30min |
| **å®éªŒ** | RTX 3060 | 12GB | 16GB | 10M | 5-10min |
| **æœ¬åœ°è®­ç»ƒ** | **RTX 5060** | **8GB** | **32GB** | **70M** | **30-40min** |
| **ä¸“ä¸šå¼€å‘** | RTX 4090 | 24GB | 64GB | 200M+ | 10-20min |
| **Macç”¨æˆ·** | **M4 Pro** | **32GBç»Ÿä¸€** | - | **68M** | **40-60min** |

*åŸºäº 10k training steps

### å¿«é€Ÿé€‰æ‹©

```python
# RTX 5060 / 3060 / 4060 ç”¨æˆ·
from config import get_rtx5060_config, get_rtx5060_train_config
python train_rtx5060.py

# Apple M4 Pro / M3 Pro / M2 Pro ç”¨æˆ·
from config import get_m4pro_config, get_m4pro_train_config
python train_m4pro.py

# å…¶ä»–é…ç½®
from config import get_small_config, get_medium_config, get_large_config
python train.py
```

è¯¦ç»†é…ç½®æŒ‡å—:
- **RTX 5060**: [RTX5060_GUIDE.md](RTX5060_GUIDE.md)
- **å¿«é€Ÿå‚è€ƒ**: [QUICK_REFERENCE.md](QUICK_REFERENCE.md)

---

## ğŸ”„ ä¸ä¸»å·¥ç¨‹çš„å…³ç³»

**æ ¸å¿ƒåŸåˆ™**: æ•™ç¨‹æ˜¯ä¸»å·¥ç¨‹çš„**å±•ç¤ºçª—å£**,ä¸æ˜¯ç‹¬ç«‹åˆ†æ”¯ã€‚

```
tutorials/              src/llm_foundry/
(æ•™å­¦å‹å¥½)          âŸ·   (å·¥ç¨‹åŒ–)

- å•æ–‡ä»¶å®Œæ•´å®ç°      âŸ·   - æ¨¡å—åŒ–è®¾è®¡
- è¯¦ç»†æ³¨é‡Š            âŸ·   - ç®€æ´ä»£ç 
- æ•™å­¦ä¼˜å…ˆ            âŸ·   - æ€§èƒ½ä¼˜å…ˆ
- ç‹¬ç«‹è¿è¡Œ            âŸ·   - åŒ…ç®¡ç†

åŠŸèƒ½å®Œå…¨å¯¹ç­‰,åªæ˜¯ç»„ç»‡æ–¹å¼ä¸åŒ
```

---

## ğŸ“š æ¨èé˜…è¯»

### ç»å…¸è®ºæ–‡
1. **Attention Is All You Need** (Transformer åŸè®ºæ–‡)
2. **GPT-3: Language Models are Few-Shot Learners**
3. **Training language models to follow instructions with human feedback** (InstructGPT)
4. **LLaMA: Open and Efficient Foundation Language Models**
5. **Direct Preference Optimization** (DPO)

### å¼€æºé¡¹ç›®
- **Hugging Face Transformers**: æœ€æµè¡Œçš„ LLM åº“
- **LLaMA 2**: Meta å¼€æºçš„é«˜è´¨é‡æ¨¡å‹
- **Mistral**: é«˜æ•ˆçš„å¼€æºæ¨¡å‹
- **DeepSpeed**: å¾®è½¯çš„åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶

### å­¦ä¹ èµ„æº
- [Karpathy's nanoGPT](https://github.com/karpathy/nanoGPT): æç®€ GPT å®ç°
- [Stanford CS224N](http://web.stanford.edu/class/cs224n/): NLP è¯¾ç¨‹
- [Hugging Face Course](https://huggingface.co/course): å…è´¹ NLP è¯¾ç¨‹

---

## ğŸ¤ è´¡çŒ®

å‘ç°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®? æ¬¢è¿:
- æäº¤ Issue
- åˆ›å»º Pull Request
- åˆ†äº«ä½ çš„è®­ç»ƒç»éªŒ

---

**ç¥å­¦ä¹ æ„‰å¿«! ğŸš€**

*ç³»ç»Ÿæ€§æŒæ¡ LLM è®­ç»ƒ,ä»ç†è®ºåˆ°å®è·µ,ä»å…¥é—¨åˆ°ç²¾é€šã€‚*
