"""分词器模块

提供基于 SentencePiece 的 BPE 分词器。
"""

from .sp_tokenizer import Tokenizer

__all__ = ['Tokenizer']
